{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing pyspark Intallation\n",
    "import findspark\n",
    "findspark.init('C:\\Spark')\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Win10.eu2d4xqpkiwuzc50gvspb3qxbb.bx.internal.cloudapp.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x196a2bdccf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PySpark Aggregate Functions\n",
    "\n",
    "    - approx_count_distinct\n",
    "    - avg\n",
    "    - collect_list\n",
    "    - collect_set\n",
    "    - countDistinct\n",
    "    - count\n",
    "    - grouping\n",
    "    - first\n",
    "    - last\n",
    "    - kurtosis\n",
    "    - max\n",
    "    - min\n",
    "    - mean\n",
    "    - skewness\n",
    "    - stddev\n",
    "    - stddev_samp\n",
    "    - stddev_pop\n",
    "    - sum\n",
    "    - sumDistinct\n",
    "    - variance\n",
    "    - var_samp\n",
    "    - var_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+----------------+\n",
      "|Item_Name|Quantity|Price/item|       Shop_Name|\n",
      "+---------+--------+----------+----------------+\n",
      "|Chocolate|      12|        20|      Deck Store|\n",
      "|  Kurkure|      20|        25|Mooney ShopStore|\n",
      "| Biscuits|       6|        45|      Deck Store|\n",
      "|      Pen|       2|         5|     Shyam Store|\n",
      "|   Sheets|       5|        10|     Shyam Store|\n",
      "+---------+--------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV File\n",
    "csv_file = 'data/3.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",True).csv(csv_file)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item_Name: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Price/item: string (nullable = true)\n",
      " |-- Shop_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Datatype of the Column 'Quantity'\n",
    "df = df.withColumn(\"Quantity\",df.Quantity.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item_Name: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Price/item: string (nullable = true)\n",
      " |-- Shop_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+----------------+----------+\n",
      "|Item_Name|Quantity|Price/item|       Shop_Name|Total Cost|\n",
      "+---------+--------+----------+----------------+----------+\n",
      "|Chocolate|      12|        20|      Deck Store|     240.0|\n",
      "|  Kurkure|      20|        25|Mooney ShopStore|     500.0|\n",
      "| Biscuits|       6|        45|      Deck Store|     270.0|\n",
      "|      Pen|       2|         5|     Shyam Store|      10.0|\n",
      "|   Sheets|       5|        10|     Shyam Store|      50.0|\n",
      "|    Novel|      10|       100|Mooney ShopStore|    1000.0|\n",
      "+---------+--------+----------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing all SQL functions\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_avg = df.withColumn(\"Total Cost\",col(\"Quantity\") * col(\"Price/item\"))\n",
    "\n",
    "#View dataframe\n",
    "df_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Average Cost|\n",
      "+------------+\n",
      "|       345.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying average function\n",
    "\n",
    "# avg\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_avg.select(avg(\"Total Cost\").alias(\"Average Cost\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Total Items|\n",
      "+-----------+\n",
      "|         55|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sum\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df_avg.select(sum(\"Quantity\").alias(\"Total Items\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|       Shop_Name|sum(Quantity)|\n",
      "+----------------+-------------+\n",
      "|     Shyam Store|            7|\n",
      "|Mooney ShopStore|           30|\n",
      "|      Deck Store|           18|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy\n",
    "\n",
    "df.groupBy(\"Shop_Name\").sum(\"Quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+----------------+----------+\n",
      "|Item_Name|Quantity|Price/item|       Shop_Name|Total Cost|\n",
      "+---------+--------+----------+----------------+----------+\n",
      "|Chocolate|      12|        20|      Deck Store|     240.0|\n",
      "|  Kurkure|      20|        25|Mooney ShopStore|     500.0|\n",
      "| Biscuits|       6|        45|      Deck Store|     270.0|\n",
      "|      Pen|       2|         5|     Shyam Store|      10.0|\n",
      "|   Sheets|       5|        10|     Shyam Store|      50.0|\n",
      "|    Novel|      10|       100|Mooney ShopStore|    1000.0|\n",
      "+---------+--------+----------+----------------+----------+\n",
      "\n",
      "+----------------+---------------+\n",
      "|       Shop_Name|avg(Total Cost)|\n",
      "+----------------+---------------+\n",
      "|     Shyam Store|           30.0|\n",
      "|Mooney ShopStore|          750.0|\n",
      "|      Deck Store|          255.0|\n",
      "+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question:Calculate the average amount earn by each shopstore.\n",
    "\n",
    "#Create a new column\n",
    "\n",
    "df_avg=df.withColumn(\"Total Cost\",col(\"Quantity\")*col(\"Price/item\"))\n",
    "df_avg.show()\n",
    "\n",
    "#Average money earn\n",
    "df_avg.groupBy(\"Shop_Name\").avg(\"Total Cost\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|       Shop_Name|max(Quantity)|\n",
      "+----------------+-------------+\n",
      "|     Shyam Store|            5|\n",
      "|Mooney ShopStore|           20|\n",
      "|      Deck Store|           12|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question:Find the quantity of item purchased maximum from each shopstore?\n",
    "\n",
    "df.groupBy(\"Shop_Name\").max(\"Quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|Maximum Quantity|\n",
      "+----------------+\n",
      "|              20|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "df.select(max(\"Quantity\").alias(\"Maximum Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|       Shop_Name|min(Quantity)|\n",
      "+----------------+-------------+\n",
      "|     Shyam Store|            2|\n",
      "|Mooney ShopStore|           10|\n",
      "|      Deck Store|            6|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min : min() returns the minimum value in a given column.\n",
    "\n",
    "df.groupBy(\"Shop_Name\").min(\"Quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(Quantity)|\n",
      "+---------------+\n",
      "|              6|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count : count() returns the number of elements in a column.\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df.select(count(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       Shop_Name|\n",
      "+----------------+\n",
      "|     Shyam Store|\n",
      "|Mooney ShopStore|\n",
      "|      Deck Store|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# distinct : distinct() returns only unique values of a column.\n",
    "\n",
    "df.select(df[\"Shop_Name\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|collect_list(Shop_Name)                                                               |\n",
      "+--------------------------------------------------------------------------------------+\n",
      "|[Deck Store, Mooney ShopStore, Deck Store, Shyam Store, Shyam Store, Mooney ShopStore]|\n",
      "+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collect_list : collect_list() function returns all values from an input column with duplicates.\n",
    "\n",
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "df.select(collect_list(\"Shop_Name\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|collect_set(Shop_Name)                     |\n",
      "+-------------------------------------------+\n",
      "|[Deck Store, Shyam Store, Mooney ShopStore]|\n",
      "+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collect_set() function returns all values from an input column with duplicate values eliminated.\n",
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "df.select(collect_set(\"Shop_Name\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg:34.166666666666664\n"
     ]
    }
   ],
   "source": [
    "# Avaerage Salary\n",
    "\n",
    "print(\"Avg:\" + str (df.select(avg('Price/item')).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT Shop_Name)|\n",
      "+-------------------------+\n",
      "|                        3|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# countDistinct Aggregate Function\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df.select(countDistinct(\"Shop_Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|first(Shop_Name)|\n",
      "+----------------+\n",
      "|Deck Store      |\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first function\n",
    "from pyspark.sql.functions import first\n",
    "\n",
    "df.select(first(\"Shop_Name\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last function\n",
    "\n",
    "df.select(last(\"Shop_Name\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+----------------+\n",
      "|Item_Name|Quantity|Price/item|       Shop_Name|\n",
      "+---------+--------+----------+----------------+\n",
      "|Chocolate|      12|        20|      Deck Store|\n",
      "|  Kurkure|      20|        25|Mooney ShopStore|\n",
      "| Biscuits|       6|        45|      Deck Store|\n",
      "|      Pen|       2|         5|     Shyam Store|\n",
      "|   Sheets|       5|        10|     Shyam Store|\n",
      "|    Novel|      10|       100|Mooney ShopStore|\n",
      "+---------+--------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|kurtosis(Quantity) |\n",
      "+-------------------+\n",
      "|-0.5862989683145523|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kurtosis function\n",
    "from pyspark.sql.functions import kurtosis\n",
    "\n",
    "df.select(kurtosis('Quantity')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|avg(Quantity)    |\n",
      "+-----------------+\n",
      "|9.166666666666666|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean function\n",
    "from pyspark.sql.functions import mean\n",
    "\n",
    "df.select(mean('Quantity')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|skewness(Quantity)|\n",
      "+------------------+\n",
      "|0.6872898280823618|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# skewness function\n",
    "from pyspark.sql.functions import skewness\n",
    "\n",
    "df.select(skewness('Quantity')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+--------------------+\n",
      "|stddev_samp(Quantity)|stddev_samp(Quantity)|stddev_pop(Quantity)|\n",
      "+---------------------+---------------------+--------------------+\n",
      "|6.400520812142295    |6.400520812142295    |5.842849380986035   |\n",
      "+---------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stddev :\n",
    "# stddev_samp : function returns the sample standard deviation of values in a column\n",
    "# stddev_pop : function returns the population standard deviation of the values in a column\n",
    "\n",
    "from pyspark.sql.functions import stddev,stddev_samp,stddev_pop\n",
    "\n",
    "df.select(stddev(\"Quantity\"), stddev_samp(\"Quantity\"),stddev_pop(\"Quantity\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|sum(DISTINCT Quantity)|\n",
      "+----------------------+\n",
      "|55                    |\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sumDistinct :\n",
    "from pyspark.sql.functions import sumDistinct\n",
    "\n",
    "df.select(sumDistinct(\"Quantity\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-----------------+\n",
      "|var_samp(Quantity)|var_samp(Quantity)|var_pop(Quantity)|\n",
      "+------------------+------------------+-----------------+\n",
      "|40.96666666666667 |40.96666666666667 |34.13888888888889|\n",
      "+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# variance()\n",
    "# var_samp() :  function returns the unbiased variance of the values in a column.\n",
    "# var_pop() : function returns the population variance of the values in a column.\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import variance,var_samp,var_pop\n",
    "df.select(variance(\"Quantity\"),var_samp(\"Quantity\"),var_pop(\"Quantity\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
