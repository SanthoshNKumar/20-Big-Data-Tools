{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing pyspark Intallation\n",
    "import findspark\n",
    "findspark.init('C:\\Spark')\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Win10.eu2d4xqpkiwuzc50gvspb3qxbb.bx.internal.cloudapp.net:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x20fbf3fed30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|    species|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|          3|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|           5|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\",True).csv(\"data/IRIS.csv\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species    |\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|5.1         |3.5        |1.4         |0.2        |Iris-setosa|\n",
      "|4.9         |3          |1.4         |0.2        |Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display 2 rows and full column contents\n",
    "\n",
    "df.show(2,truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|    species|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|          3|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display 2 rows & column values 25 characters\n",
    "\n",
    "df.show(2,truncate=25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------\n",
      " sepal_length | 5.1         \n",
      " sepal_width  | 3.5         \n",
      " petal_length | 1.4         \n",
      " petal_width  | 0.2         \n",
      " species      | Iris-setosa \n",
      "-RECORD 1-------------------\n",
      " sepal_length | 4.9         \n",
      " sepal_width  | 3           \n",
      " petal_length | 1.4         \n",
      " petal_width  | 0.2         \n",
      " species      | Iris-setosa \n",
      "-RECORD 2-------------------\n",
      " sepal_length | 4.7         \n",
      " sepal_width  | 3.2         \n",
      " petal_length | 1.3         \n",
      " petal_width  | 0.2         \n",
      " species      | Iris-setosa \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame rows & columns vertically\n",
    "\n",
    "df.show(n=3,truncate=25,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: string (nullable = true)\n",
      " |-- sepal_width: string (nullable = true)\n",
      " |-- petal_length: string (nullable = true)\n",
      " |-- petal_width: string (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('petal_width', 'string')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data type of “Age”column.\n",
    "\n",
    "df.select(\"petal_width\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: string (nullable = true)\n",
      " |-- sepal_width: string (nullable = true)\n",
      " |-- petal_length: string (nullable = true)\n",
      " |-- petal_width: integer (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change Column type using cast\n",
    "\n",
    "df_datatype=df.withColumn(\"petal_width\",df[\"petal_width\"].cast(\"int\"))\n",
    "\n",
    "df_datatype.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- sepal_length: double (nullable = true)\n",
      "\n",
      "+-----------+------------+\n",
      "|petal_width|sepal_length|\n",
      "+-----------+------------+\n",
      "|        0.2|         5.1|\n",
      "|        0.2|         4.9|\n",
      "|        0.2|         4.7|\n",
      "|        0.2|         4.6|\n",
      "|        0.2|         5.0|\n",
      "+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change Column type using selectExpr\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "df_new = df.selectExpr(\"cast(petal_width as Double ) petal_width\", \"cast(sepal_length as Double) sepal_length\")\n",
    "\n",
    "df_new.printSchema()\n",
    "\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- species: string (nullable = true)\n",
      " |-- sepal_length: float (nullable = true)\n",
      "\n",
      "+-----------+------------+\n",
      "|    species|sepal_length|\n",
      "+-----------+------------+\n",
      "|Iris-setosa|         5.1|\n",
      "|Iris-setosa|         4.9|\n",
      "|Iris-setosa|         4.7|\n",
      "|Iris-setosa|         4.6|\n",
      "|Iris-setosa|         5.0|\n",
      "+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Change Column type using SQL Expression\n",
    "\n",
    "df.createOrReplaceTempView(\"Table\")\n",
    "\n",
    "df_sql = spark.sql(\"SELECT STRING(species),Float(sepal_length) from Table\")\n",
    "df_sql.printSchema()\n",
    "\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Change the value of an existing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|    species|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|        14.0|        0.2|Iris-setosa|\n",
      "|         4.9|          3|        14.0|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|        13.0|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|        15.0|        0.2|Iris-setosa|\n",
      "|           5|        3.6|        14.0|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_value = df.withColumn(\"petal_length\",col(\"petal_length\") * 10)\n",
    "\n",
    "df_value.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive column from existing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|    species|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|          3|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|           5|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = df.withColumn(\"petal_length\",(col(\"petal_length\") * 100) / 100)\n",
    "\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename a Dataframe Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-------------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width_1|    species|\n",
      "+------------+-----------+------------+-------------+-----------+\n",
      "|         5.1|        3.5|         1.4|          0.2|Iris-setosa|\n",
      "|         4.9|          3|         1.4|          0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|          0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|          0.2|Iris-setosa|\n",
      "|           5|        3.6|         1.4|          0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "re_df = df.withColumnRenamed(\"petal_width\",\"petal_width_1\")\n",
    "re_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new column with constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|    species|COllege|\n",
      "+------------+-----------+------------+-----------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|  MITRC|\n",
      "|         4.9|          3|         1.4|        0.2|Iris-setosa|  MITRC|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|  MITRC|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|  MITRC|\n",
      "|           5|        3.6|         1.4|        0.2|Iris-setosa|  MITRC|\n",
      "+------------+-----------+------------+-----------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lit\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "new_col = df.withColumn(\"COllege\",lit(\"MITRC\"))\n",
    "new_col.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|    species|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|          3|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|           5|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop a column\n",
    "\n",
    "drop_df = new_col.drop(\"COllege\")\n",
    "\n",
    "drop_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greatest\n",
    "\n",
    "from pyspark.sql.functions import greatest,col\n",
    "\n",
    "df1=df.withColumn(\"large\",greatest(col(\"level1\"),col(\"level2\"),col(\"level3\"),col(\"level4\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least\n",
    "\n",
    "from pyspark.sql.functions import least,col\n",
    "\n",
    "df2=df.withColumn(\"Small\",least(col(\"level1\"),col(\"level2\"),col(\"level3\"),col(\"level4\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
