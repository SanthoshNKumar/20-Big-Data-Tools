{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Win10.eu2d4xqpkiwuzc50gvspb3qxbb.bx.internal.cloudapp.net:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d8b7aa6550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing pyspark Intallation\n",
    "import findspark\n",
    "findspark.init('C:\\Spark')\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+-------+------+\n",
      "|EmpId|EmpName|Gender|Dept No|Salary|\n",
      "+-----+-------+------+-------+------+\n",
      "|  101|   Beck|     F|      1|  8900|\n",
      "|  102|    Joe|     M|      3|  7800|\n",
      "|  103|  Peach|     F|      1| 10000|\n",
      "|  104| Bengie|     M|      2|  6000|\n",
      "|  105|  Barko|     M|      2| 11000|\n",
      "+-----+-------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV File\n",
    "csv_file = 'data/4.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",True).csv(csv_file)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmpId: string (nullable = true)\n",
      " |-- EmpName: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Dept No: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+-------+------+\n",
      "|EmpId|EmpName|Gender|Dept No|Salary|\n",
      "+-----+-------+------+-------+------+\n",
      "|  101|   Beck|     F|      1|  8900|\n",
      "|  103|  Peach|     F|      1| 10000|\n",
      "+-----+-------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe Filter() \n",
    "# Get the data 'Dept No' is equal to '1'\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.filter(col(\"Dept No\") ==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+-------+------+\n",
      "|EmpId|EmpName|Gender|Dept No|Salary|\n",
      "+-----+-------+------+-------+------+\n",
      "|  103|  Peach|     F|      1| 10000|\n",
      "|  105|  Barko|     M|      2| 11000|\n",
      "+-----+-------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQLexpression\n",
    "\n",
    "df.filter(col(\"Salary\")>9000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+-------+------+\n",
      "|EmpId|EmpName|Gender|Dept No|Salary|\n",
      "+-----+-------+------+-------+------+\n",
      "|  104| Bengie|     M|      2|  6000|\n",
      "|  105|  Barko|     M|      2| 11000|\n",
      "+-----+-------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering with multiple conditions\n",
    "    # AND(&&)\n",
    "    # NOT(!)\n",
    "    # OR(||)\n",
    "    \n",
    " #Filter with Multiple condition\n",
    "columns = [\"Names\",\"Languages\",'Sex']\n",
    "row=[[[\"Rohit\",\"Gupta\"],[\"Python\",\"C\"],\"M\"],\n",
    "     [[\"Shanu\",\"Sisodiya\"],[\"C++\",\"Java\",\"Python\"],\"F\"],\n",
    "     [[\"Parth\",\"Sisodiya\"],[\"C++\",\"C#\",\"Java\"],\"M\"]]\n",
    "\n",
    "df.filter((df[\"Gender\"]==\"M\") & (df[\"Dept No\"]==2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|            Names|          Languages|Gender|\n",
      "+-----------------+-------------------+------+\n",
      "|   [Rohit, Gupta]|        [Python, C]|     M|\n",
      "|[Shanu, Sisodiya]|[C++, Java, Python]|     F|\n",
      "|[Parth, Sisodiya]|    [C++, C#, Java]|     M|\n",
      "+-----------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Names\",\"Languages\",'Gender']\n",
    "\n",
    "row=[[[\"Rohit\",\"Gupta\"],[\"Python\",\"C\"],\"M\"],\n",
    "     [[\"Shanu\",\"Sisodiya\"],[\"C++\",\"Java\",\"Python\"],\"F\"],\n",
    "     [[\"Parth\",\"Sisodiya\"],[\"C++\",\"C#\",\"Java\"],\"M\"]]\n",
    "\n",
    "# Create RDD\n",
    "rdd = spark.sparkContext.parallelize(row)\n",
    "\n",
    "# Using toDF() function\n",
    "df = rdd.toDF()\n",
    "\n",
    "# Column names to the DataFrame use toDF() method with column\n",
    "df = rdd.toDF(columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|            Names|          Languages|Gender|\n",
      "+-----------------+-------------------+------+\n",
      "|   [Rohit, Gupta]|        [Python, C]|     M|\n",
      "|[Shanu, Sisodiya]|[C++, Java, Python]|     F|\n",
      "+-----------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe contains three columns 'Name', 'Language' and 'Gender'\n",
    "\n",
    "# Filtering on an array column\n",
    "from pyspark.sql.functions import array_contains\n",
    "\n",
    "#Filtering conditions\n",
    "df.filter(array_contains(df[\"Languages\"],\"Python\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
