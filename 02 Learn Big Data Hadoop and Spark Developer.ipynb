{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data Hadoop and Spark Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 1 : Introduction to Big Data and Hadoop\n",
    "            - Introduction to Big Data and Hadoop\n",
    "            - Introduction to Big Data\n",
    "            - Big Data Analytics\n",
    "            - What is Big Data\n",
    "            - Four Vs Of Big Data\n",
    "            - Case Study: Royal Bank of Scotland\n",
    "            - Challenges of Traditional System\n",
    "            - Distributed Systems\n",
    "            - Introduction to Hadoop\n",
    "            - Components of Hadoop Ecosystem\n",
    "            - Commercial Hadoop Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 2:  Hadoop Architecture,Distributed Storage (HDFS) and YARN\n",
    "            - Hadoop Architecture Distributed Storage (HDFS) and YARN\n",
    "            - What Is HDFS\n",
    "            - Need for HDFS\n",
    "            - Regular File System vs HDFS\n",
    "            - Characteristics of HDFS\n",
    "            - HDFS Architecture and Components\n",
    "            - High Availability Cluster Implementations\n",
    "            - HDFS Component File System Namespace\n",
    "            - Data Block Split\n",
    "            - Data Replication Topology\n",
    "            - HDFS Command Line\n",
    "            - Demo: Common HDFS Commands\n",
    "            - HDFS Command Line\n",
    "            - YARN Introduction\n",
    "            - YARN Use Case\n",
    "            - YARN and Its Architecture\n",
    "            - Resource Manager\n",
    "            - How Resource Manager Operates\n",
    "            - Application Master\n",
    "            - How YARN Runs an Application\n",
    "            - Tools for YARN Developers\n",
    "            - Demo: Walkthrough of Cluster Part One\n",
    "            - Demo: Walkthrough of Cluster Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 3: Data Ingestion into Big Data Systems and ETL\n",
    "            - Data Ingestion into Big Data Systems and ETL\n",
    "            - Data Ingestion Overview Part One\n",
    "            - Data Ingestion\n",
    "            - Apache Sqoop\n",
    "            - Sqoop and Its Uses\n",
    "            - Sqoop Processing\n",
    "            - Sqoop Import Process\n",
    "\n",
    "            - Assisted Practice: Import into Sqoop\n",
    "            - Sqoop Connectors\n",
    "            - Demo: Importing and Exporting Data from MySQL to HDFS\n",
    "\n",
    "            - Apache Sqoop\n",
    "            - Apache Flume\n",
    "            - Flume Model\n",
    "            - Scalability in Flume\n",
    "            - Components in Flumeâ€™s Architecture\n",
    "            - Configuring Flume Components\n",
    "            - Demo: Ingest Twitter Data\n",
    "            \n",
    "            - Apache Kafka\n",
    "            - Aggregating User Activity Using Kafka\n",
    "            - Kafka Data Model\n",
    "            - Partitions\n",
    "            - Apache Kafka Architecture\n",
    "            - Producer Side API Example\n",
    "            - Consumer Side API\n",
    "            - Demo: Setup Kafka Cluster\n",
    "            - Consumer Side API Example\n",
    "            - Kafka Connect\n",
    "            - Key Takeaways\n",
    "            - Demo: Creating Sample Kafka Data Pipeline using Producer and Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 4 : Distributed Processing - MapReduce Framework and Pig\n",
    "            - Distributed Processing MapReduce Framework and Pig\n",
    "            - Distributed Processing in MapReduce\n",
    "            - Word Count Example\n",
    "            - Map Execution Phases\n",
    "            - Map Execution Distributed Two Node Environment\n",
    "            - MapReduce Jobs\n",
    "            - Hadoop MapReduce Job Work Interaction\n",
    "            - Setting Up the Environment for MapReduce Development\n",
    "            - Set of Classes\n",
    "            - Creating a New Project\n",
    "            - Advanced MapReduce\n",
    "            - Data Types in Hadoop\n",
    "            - OutputFormats in MapReduce\n",
    "            - Using Distributed Cache\n",
    "            - Joins in MapReduce\n",
    "            - Replicated Join\n",
    "            - Introduction to Pig\n",
    "            - Components of Pig\n",
    "            - Pig Data Model\n",
    "            - Pig Interactive Modes\n",
    "            - Pig Operations\n",
    "            - Various Relations Performed by Developers\n",
    "            - Demo: Analyzing Web Log Data Using MapReduce\n",
    "            - Demo: Analyzing Sales Data and Solving KPIs using PIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 5: Apache Hive\n",
    "            - Apache Hive\n",
    "            - Hive SQL over Hadoop MapReduce\n",
    "            - Hive Architecture\n",
    "            - Interfaces to Run Hive Queries\n",
    "            - Running Beeline from Command Line\n",
    "            - Hive Metastore\n",
    "            - Hive DDL and DML\n",
    "            - Creating New Table\n",
    "            - Data Types\n",
    "            - Validation of Data\n",
    "            - File Format Types\n",
    "            - Data Serialization\n",
    "            - Hive Table and Avro Schema\n",
    "            - Hive Optimization Partitioning Bucketing and Sampling\n",
    "            - Non Partitioned Table\n",
    "            - Data Insertion\n",
    "            - Dynamic Partitioning in Hive\n",
    "            - Bucketing\n",
    "            - What Do Buckets Do\n",
    "            - Hive Analytics UDF and UDAF\n",
    "            Assisted Practice: Synchronization\n",
    "            - Other Functions of Hive\n",
    "            - Demo: Real-Time Analysis and Data Filteration\n",
    "            - Demo: Real-World Problem\n",
    "            - Demo: Data Representation and Import using Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 6: NoSQL Databases - HBase\n",
    "            - NoSQL Databases HBase\n",
    "            - NoSQL Introduction\n",
    "\n",
    "            Demo: Yarn Tuning\n",
    "            - HBase Overview\n",
    "            - HBase Architecture\n",
    "            - Data Model\n",
    "            - Connecting to HBase\n",
    "            - HBase Shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 7: Basics of Functional Programming and Scala\n",
    "            - Basics of Functional Programming and Scala\n",
    "            - Introduction to Scala\n",
    "            - Demo: Scala Installation\n",
    "            - Functional Programming\n",
    "            - Programming with Scala\n",
    "            - Demo: Basic Literals and Arithmetic Operators\n",
    "            - Demo: Logical Operators\n",
    "            - Type Inference Classes Objects and Functions in Scala\n",
    "            - Demo: Type Inference Functions Anonymous Function and Class\n",
    "            - Collections\n",
    "            - Types of Collections\n",
    "            - Demo: Five Types of Collections\n",
    "            - Demo: Operations on List\n",
    "            - Scala REPL\n",
    "            - Assisted Practice: Scala\n",
    "            - Demo: Features of Scala REPL\n",
    "            - Key Takeaways\n",
    "            - Knowledge Check\n",
    "            - Basics of Functional Programming and Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 8: Apache Spark Next Generation Big Data Framework\n",
    "            - Apache Spark Next Generation Big Data Framework\n",
    "            - History of Spark\n",
    "            - Limitations of MapReduce in Hadoop\n",
    "            - Introduction to Apache Spark\n",
    "            - Components of Spark\n",
    "            - Application of In-Memory Processing\n",
    "            - Hadoop Ecosystem vs Spark\n",
    "            - Advantages of Spark\n",
    "            - Spark Architecture\n",
    "            -  Spark Cluster in Real World\n",
    "            -  Demo: Running a Scala Programs in Spark Shell\n",
    "            -  Demo: Setting Up Execution Environment in IDE\n",
    "            -  Demo: Spark Web UI\n",
    "            -  Key Takeaways\n",
    "            - Knowledge Check\n",
    "            - Apache Spark Next Generation Big Data Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 9 Spark Core Processing RDD\n",
    "            - Processing RDD\n",
    "            - Introduction to Spark RDD\n",
    "            - RDD in Spark\n",
    "            - Creating Spark RDD\n",
    "            - Pair RDD\n",
    "            - RDD Operations\n",
    "            - Demo: Spark Transformation Detailed Exploration Using Scala Examples\n",
    "            - Demo: Spark Action Detailed Exploration Using Scala\n",
    "            - Caching and Persistence\n",
    "            - Storage Levels\n",
    "            -  Lineage and DAG\n",
    "            -  Need for DAG\n",
    "            -  Debugging in Spark\n",
    "            -  Partitioning in Spark\n",
    "            -  Scheduling in Spark\n",
    "            -  Shuffling in Spark\n",
    "            -  Sort Shuffle\n",
    "            -  Aggregating Data with Pair RDD\n",
    "            -  Demo: Spark Application with Data Written Back to HDFS and Spark UI\n",
    "            -  Demo: Changing Spark Application Parameters\n",
    "            -  Demo: Handling Different File Formats\n",
    "            -  Demo: Spark RDD with Real-World Application\n",
    "            -  Demo: Optimizing Spark Jobs\n",
    "            - Assisted Practice: Changing Spark Application Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 10 Spark SQL - Processing DataFrames\n",
    "            -  Spark SQL Processing DataFrames\n",
    "            -  Spark SQL Introduction\n",
    "            -  Spark SQL Architecture\n",
    "            -  DataFrames\n",
    "            -  Demo: Handling Various Data Formats\n",
    "            -  Demo: Implement Various DataFrame Operations\n",
    "            -  Demo: UDF and UDAF\n",
    "            -  Interoperating with RDDs\n",
    "            -  Demo: Process DataFrame Using SQL Query\n",
    "            -  RDD vs DataFrame vs Dataset\n",
    "            -  Processing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 11 Spark MLLib - Modelling BigData with Spark\n",
    "            -  Spark MLlib Modeling Big Data with Spark\n",
    "            -  Role of Data Scientist and Data Analyst in Big Data\n",
    "            -  Analytics in Spark\n",
    "            -  Machine Learning\n",
    "            -  Supervised Learning\n",
    "            -  Demo: Classification of Linear SVM\n",
    "            -  Demo: Linear Regression with Real World Case Studies\n",
    "            -  Unsupervised Learning\n",
    "            -  Demo: Unsupervised Clustering K-Means\n",
    "            - Assisted Practice: Unsupervised Clustering K-\n",
    "            -  Reinforcement Learning\n",
    "            -  Semi-Supervised Learning\n",
    "            -  Overview of MLlib\n",
    "            -  MLlib Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 12 Stream Processing Frameworks and Spark Streaming\n",
    "            -  Stream Processing Frameworks and Spark Streaming\n",
    "            -  Streaming Overview\n",
    "            -  Real-Time Processing of Big Data\n",
    "            -  Data Processing Architectures\n",
    "            -  Demo: Real-Time Data Processing\n",
    "            -  Spark Streaming\n",
    "            -  Demo: Writing Spark Streaming Application\n",
    "            -  Introduction to DStreams\n",
    "            -  Transformations on DStreams\n",
    "            -  Design Patterns for Using ForeachRDD\n",
    "            -  State Operations\n",
    "            -  Windowing Operations\n",
    "            -  Join Operations stream-dataset Join\n",
    "            -  Demo: Windowing of Real-Time Data Processing\n",
    "            -  Streaming Sources\n",
    "            -  Demo: Processing Twitter Streaming Data\n",
    "            -  Structured Spark Streaming\n",
    "            -  Use Case Banking Transactions\n",
    "            -  Structured Streaming Architecture Model and Its Components\n",
    "            -  Output Sinks\n",
    "            -  Structured Streaming APIs\n",
    "            -  Constructing Columns in Structured Streaming\n",
    "            -  Windowed Operations on Event-Time\n",
    "            -  Use Cases\n",
    "            -  Demo: Streaming Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lesson 13 Spark GraphX\n",
    "        -  Spark GraphX\n",
    "        -  Introduction to Graph\n",
    "        -  Graphx in Spark\n",
    "        -  Graph Operators\n",
    "        -  Join Operators\n",
    "        -  Graph Parallel System\n",
    "        -  Algorithms in Spark\n",
    "        -  Pregel API\n",
    "        -  Use Case of GraphX\n",
    "        -  Demo: GraphX Vertex Predicate\n",
    "        -  Demo: Page Rank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Projects:\n",
    "    Car Insurance Analysis\n",
    "    Transactional Data Analysis\n",
    "    K-Means clustering for telecommunication domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
